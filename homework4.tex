\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={131homework-4},
            pdfauthor={Hector He},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\title{131homework-4}
\author{Hector He}
\date{4/29/2022}

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{'~/Desktop/Spring 2022/PSTAT 131/homework/homework-4/data/titanic.csv'}\NormalTok{)}
\KeywordTok{library}\NormalTok{(dplyr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'dplyr'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     filter, lag
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidymodels)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages -------------------------------------- tidymodels 0.2.0 --
\end{verbatim}

\begin{verbatim}
## v broom        0.8.0     v rsample      0.1.1
## v dials        0.1.1     v tibble       3.1.7
## v ggplot2      3.3.6     v tidyr        1.2.0
## v infer        1.0.0     v tune         0.2.0
## v modeldata    0.1.1     v workflows    0.2.6
## v parsnip      0.2.1     v workflowsets 0.2.1
## v purrr        0.3.4     v yardstick    0.0.9
## v recipes      0.2.0
\end{verbatim}

\begin{verbatim}
## -- Conflicts ----------------------------------------- tidymodels_conflicts() --
## x purrr::discard() masks scales::discard()
## x dplyr::filter()  masks stats::filter()
## x dplyr::lag()     masks stats::lag()
## x recipes::step()  masks stats::step()
## * Search for functions across packages at https://www.tidymodels.org/find/
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --
\end{verbatim}

\begin{verbatim}
## v readr   2.1.2     v forcats 0.5.1
## v stringr 1.4.0
\end{verbatim}

\begin{verbatim}
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x readr::col_factor() masks scales::col_factor()
## x purrr::discard()    masks scales::discard()
## x dplyr::filter()     masks stats::filter()
## x stringr::fixed()    masks recipes::fixed()
## x dplyr::lag()        masks stats::lag()
## x readr::spec()       masks yardstick::spec()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readr)}
\KeywordTok{tidymodels_prefer}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Question 1

Split the data, stratifying on the outcome variable, survived. You
should choose the proportions to split the data into. Verify that the
training and testing data sets have the appropriate number of
observations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic <-}\StringTok{ }\NormalTok{titanic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{survived =} \KeywordTok{factor}\NormalTok{(survived, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{'Yes'}\NormalTok{,}\StringTok{'No'}\NormalTok{))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pclass =} \KeywordTok{factor}\NormalTok{(pclass, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{'1'}\NormalTok{,}\StringTok{'2'}\NormalTok{,}\StringTok{'3'}\NormalTok{)))}
\KeywordTok{head}\NormalTok{(titanic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   passenger_id survived pclass
## 1            1       No      3
## 2            2      Yes      1
## 3            3      Yes      3
## 4            4      Yes      1
## 5            5       No      3
## 6            6       No      3
##                                                  name    sex age sib_sp parch
## 1                             Braund, Mr. Owen Harris   male  22      1     0
## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38      1     0
## 3                              Heikkinen, Miss. Laina female  26      0     0
## 4        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35      1     0
## 5                            Allen, Mr. William Henry   male  35      0     0
## 6                                    Moran, Mr. James   male  NA      0     0
##             ticket    fare cabin embarked
## 1        A/5 21171  7.2500  <NA>        S
## 2         PC 17599 71.2833   C85        C
## 3 STON/O2. 3101282  7.9250  <NA>        S
## 4           113803 53.1000  C123        S
## 5           373450  8.0500  <NA>        S
## 6           330877  8.4583  <NA>        Q
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2000}\NormalTok{)}
\NormalTok{titanic_split <-}\StringTok{ }\KeywordTok{initial_split}\NormalTok{(titanic, }\DataTypeTok{prop =} \FloatTok{0.75}\NormalTok{, }\DataTypeTok{strata =}\NormalTok{ survived)}
\NormalTok{titanic_test <-}\StringTok{ }\KeywordTok{testing}\NormalTok{(titanic_split)}
\NormalTok{titanic_train <-}\StringTok{ }\KeywordTok{training}\NormalTok{(titanic_split)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(titanic_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 224  12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(titanic_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 667  12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic_recipe <-}\StringTok{ }\KeywordTok{recipe}\NormalTok{(survived }\OperatorTok{~}\StringTok{ }\NormalTok{pclass }\OperatorTok{+}\NormalTok{sex }\OperatorTok{+}\NormalTok{age }\OperatorTok{+}\NormalTok{sib_sp }\OperatorTok{+}\NormalTok{parch }\OperatorTok{+}\NormalTok{fare, }\DataTypeTok{data =}\NormalTok{ titanic_train) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{step_impute_linear}\NormalTok{(age, }\DataTypeTok{impute_with =} \KeywordTok{imp_vars}\NormalTok{(pclass, fare)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{step_dummy}\NormalTok{(}\KeywordTok{all_nominal_predictors}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{step_center}\NormalTok{(}\KeywordTok{all_predictors}\NormalTok{()) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{step_scale}\NormalTok{(}\KeywordTok{all_predictors}\NormalTok{()) }
\end{Highlighting}
\end{Shaded}

Question 2

Fold the training data. Use k-fold cross-validation, with k=10.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic_folds <-}\StringTok{ }\KeywordTok{vfold_cv}\NormalTok{(titanic_train, }\DataTypeTok{v =} \DecValTok{10}\NormalTok{)}
\NormalTok{titanic_folds}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## #  10-fold cross-validation 
## # A tibble: 10 x 2
##    splits           id    
##    <list>           <chr> 
##  1 <split [600/67]> Fold01
##  2 <split [600/67]> Fold02
##  3 <split [600/67]> Fold03
##  4 <split [600/67]> Fold04
##  5 <split [600/67]> Fold05
##  6 <split [600/67]> Fold06
##  7 <split [600/67]> Fold07
##  8 <split [601/66]> Fold08
##  9 <split [601/66]> Fold09
## 10 <split [601/66]> Fold10
\end{verbatim}

Question 3

In your own words, explain what we are doing in Question 2. What is
k-fold cross-validation? Why should we use it, rather than simply
fitting and testing models on the entire training set? If we did use the
entire training set, what resampling method would that be?

the k-fold cross-validation divides the training set into k=10 roughly
equal sebsets and each time holds out one of the subsets from the data
fitting as a validation set to estimate the prediction error, applying
the learned model on the remaining observations. it can be implemented
in order to find the best value of degree that yields the closest fit in
hyperparameter tuning.

Question 4

Set up workflows for 3 models:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm_titanic_train <-}\StringTok{ }\KeywordTok{logistic_reg}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{set_engine}\NormalTok{(}\StringTok{"glm"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{set_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}
\NormalTok{glm_wkflow <-}\StringTok{ }\KeywordTok{workflow}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_model}\NormalTok{(glm_titanic_train) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_recipe}\NormalTok{(titanic_recipe)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda_titanic_train <-}\StringTok{ }\KeywordTok{discrim_linear}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{set_engine}\NormalTok{(}\StringTok{"MASS"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{set_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}
\NormalTok{lda_wkflow <-}\StringTok{ }\KeywordTok{workflow}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_model}\NormalTok{(lda_titanic_train) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_recipe}\NormalTok{(titanic_recipe)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda_titanic_train <-}\StringTok{ }\KeywordTok{discrim_quad}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{set_engine}\NormalTok{(}\StringTok{"MASS"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{set_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{)}
\NormalTok{qda_wkflow <-}\StringTok{ }\KeywordTok{workflow}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_model}\NormalTok{(qda_titanic_train) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_recipe}\NormalTok{(titanic_recipe)}
\end{Highlighting}
\end{Shaded}

there will be theoretically 30 models in total to be fitted to the data
across all folds

Question 5

Fit each of the models created in Question 4 to the folded data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm_fit <-}\StringTok{ }\KeywordTok{fit_resamples}\NormalTok{(glm_wkflow, titanic_folds)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# lda_fit <- fit_resamples(lda_wkflow, titanic_folds)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# qda_fit <- fit_resamples(qda_wkflow, titanic_folds)}
\end{Highlighting}
\end{Shaded}

``Error in pkgs\$pkg{[}{[}1{]}{]} : subscript out of bounds''

due to unforeseen reasons, unable to solve this error in LDA and QDA
models when fitting them to the folded data

Question 6

Use collect\_metrics() to print the mean and standard errors of the
performance metric accuracy across all folds for each of the four
models.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{collect_metrics}\NormalTok{(glm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 6
##   .metric  .estimator  mean     n std_err .config             
##   <chr>    <chr>      <dbl> <int>   <dbl> <chr>               
## 1 accuracy binary     0.805    10  0.0130 Preprocessor1_Model1
## 2 roc_auc  binary     0.848    10  0.0168 Preprocessor1_Model1
\end{verbatim}

Question 7 Now that you've chosen a model, fit your chosen model to the
entire training dataset (not to the folds).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm_fit_train <-}\StringTok{ }\KeywordTok{fit}\NormalTok{(glm_wkflow, titanic_train)}
\end{Highlighting}
\end{Shaded}

Question 8

Finally, with your fitted model, use predict(), bind\_cols(), and
accuracy() to assess your model's performance on the testing data!
Compare your model's testing accuracy to its average accuracy across
folds. Describe what you see.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titanic_pre_glm <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(glm_fit_train, }\DataTypeTok{new_data =}\NormalTok{ titanic_test, }\DataTypeTok{type =} \StringTok{"prob"}\NormalTok{)}
\NormalTok{titanic_pre_glm <-}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(titanic_pre_glm, titanic_test)}
\KeywordTok{head}\NormalTok{(titanic_pre_glm, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 14
##    .pred_Yes .pred_No passenger_id survived pclass name       sex     age sib_sp
##        <dbl>    <dbl>        <int> <fct>    <fct>  <chr>      <chr> <dbl>  <int>
##  1    0.918    0.0815            4 Yes      1      Futrelle,~ fema~    35      1
##  2    0.102    0.898             6 No       3      Moran, Mr~ male     NA      0
##  3    0.0830   0.917             8 No       3      Palsson, ~ male      2      3
##  4    0.717    0.283            11 Yes      3      Sandstrom~ fema~     4      1
##  5    0.865    0.135            12 Yes      1      Bonnell, ~ fema~    58      0
##  6    0.739    0.261            15 No       3      Vestrom, ~ fema~    14      0
##  7    0.0628   0.937            17 No       3      Rice, Mas~ male      2      4
##  8    0.545    0.455            24 Yes      1      Sloper, M~ male     28      0
##  9    0.281    0.719            26 Yes      3      Asplund, ~ fema~    38      1
## 10    0.645    0.355            33 Yes      3      Glynn, Mi~ fema~    NA      0
## # ... with 5 more variables: parch <int>, ticket <chr>, fare <dbl>,
## #   cabin <chr>, embarked <chr>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm_acc <-}\StringTok{ }\KeywordTok{augment}\NormalTok{(glm_fit_train, }\DataTypeTok{new_data =}\NormalTok{ titanic_test) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{accuracy}\NormalTok{(}\DataTypeTok{truth =}\NormalTok{ survived, }\DataTypeTok{estimate =}\NormalTok{ .pred_class)}
\NormalTok{glm_acc}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   .metric  .estimator .estimate
##   <chr>    <chr>          <dbl>
## 1 accuracy binary         0.817
\end{verbatim}

the testing accuracy is around 81.7 \% which is slightly higher than the
average across all folds, 80.5 \%

\end{document}
